dataset:
  dataset_path: dataset/ucf_action_grouped_augmented_ttv_mp4
  path_dataset_train_csv: dataset/ucf_action_grouped_augmented_ttv_mp4/df_train.csv
  path_dataset_val_csv: dataset/ucf_action_grouped_augmented_ttv_mp4/df_val.csv
  path_dataset_test_csv: dataset/ucf_action_grouped_augmented_ttv_mp4/df_test.csv
  path_dataset_anomaly_csv: dataset/ucf_action_grouped_augmented_ttv_mp4/df_anomaly.csv
  batch_size: 8
model:
  name_time_model: r2plus1d_18 # timesformer - r2plus1d_18 - r3d
  init_dim: 512 # 768 for timesformer - 512 for r2plus1d_18 - 2048 for r3d
  num_autoencoder_layers: 3 # 2 or 3
  dim_autoencoder_layers: 384,256,128 #512,256,128
  freeze_layers: 1
  #epoch_start_unfreeze: 0
  layer_start_unfreeze: 0
  saving_dir_experiments: results_train_autoencoder/r2plus1d_18/
  saving_dir_model: v1
  num_epoch: 30
  learning_rate: 0.001
  scheduler_type: StepLR
  scheduler_step_size: 10
  lr_factor: 0.1
  dropout: 0.3
  do_train: 0
  do_test: 1
  number_of_classes: 7
data:
  num_frames_to_sample: 8
  mean: [0.43216, 0.394666, 0.37645]
  std: [0.22803, 0.22145, 0.216989]
  min_size: 128
  max_size: 171
  resize_to: 112
  permute_color_frame: 0 # 1 for timesformer - 0 for r2plus1d_18 - 0 for r3d
